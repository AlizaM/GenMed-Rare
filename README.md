# GenMed-Rare

A PyTorch-based computer-vision project that focuses on improving medical image classification by synthesizing rare cases with generative models. Binary classification experiments comparing rare disease detection with/without synthetic data augmentation using the NIH Chest X-ray dataset.

## Project Overview

Improve classification performance on rare medical cases (Fibrosis) vs common cases (Effusion) by augmenting training sets with synthetic images generated by generative models. The project uses a multi-stage pipeline to filter, organize, and train on chest X-ray images.

## Current Implementation

### Classification Pipeline
- **Dataset**: NIH Chest X-ray (filtered for Hernia, Pneumonia, Fibrosis, Effusion)
- **Task**: Binary classification (Fibrosis vs Effusion)
- **Model**: Swin Transformer (timm library)
- **Augmentations**: Medical-safe (rotation ±10°, brightness/contrast, Gaussian noise - NO flips)
- **Training**: PyTorch with TensorBoard logging, early stopping, checkpointing

### Diffusion Pipeline
- **Dataset**: Balanced diffusion dataset with medical conditions
- **Model**: Stable Diffusion 1.5 with LoRA fine-tuning
- **Task**: Generate synthetic chest X-rays conditioned on medical findings
- **Training**: HuggingFace Diffusers with mixed precision and gradient checkpointing
- **Output**: LoRA weights for generating rare medical cases

## Repository Structure

```
GenMed-Rare/
├── configs/                    # YAML configuration files
│   ├── config.yaml            # Main training configuration (Effusion vs Fibrosis)
│   ├── config_diffusion.yaml  # Diffusion model training configuration
│   └── config_test.yaml       # Quick test configuration (small dataset)
├── data/
│   ├── raw/                   # Raw data (download separately)
│   │   ├── archive.zip        # NIH Chest X-ray archive (112,120 images)
│   │   ├── Data_Entry_2017.csv # Original labels CSV
│   │   ├── train_val_list.txt # Train/val split file
│   │   └── test_list.txt      # Test split file
│   ├── interim/               # Organized data (created by scripts/filter_and_organize_data.py)
│   │   ├── train_val/         # Training + validation images organized by label
│   │   │   ├── Hernia/
│   │   │   ├── Pneumonia/
│   │   │   ├── Fibrosis/
│   │   │   └── Effusion/
│   │   ├── test/              # Test images organized by label
│   │   │   ├── Hernia/
│   │   │   ├── Pneumonia/
│   │   │   ├── Fibrosis/
│   │   │   └── Effusion/
│   │   └── filtered_data_entry.csv  # Filtered labels CSV
│   ├── processed/             # Preprocessed data (created by src/data/preprocess.py)
│   │   └── effusion_fibrosis/
│   │       ├── dataset.csv         # Unified dataset with split column
│   │       └── dataset_test.csv    # Small test dataset (320 images)
│   └── diffusion_data/        # Diffusion training data
│       └── diffusion_data_balanced/  # Balanced dataset for diffusion training
│           ├── diffusion_dataset_balanced.csv  # Image metadata
│           └── *.png          # Chest X-ray images
├── outputs/                   # Training outputs (experiment-specific)
│   ├── <experiment_name>/     # e.g., effusion_vs_fibrosis_baseline/ (classification)
│   │   ├── checkpoints/       # Model checkpoints
│   │   │   ├── best_checkpoint.pth
│   │   │   └── latest_checkpoint.pth
│   │   ├── logs/              # TensorBoard logs
│   │   └── dataset_summary.csv # Dataset statistics
│   └── diffusion_models/     # Diffusion training outputs
│       └── <experiment_name>/ # e.g., sd15_lora_fibrosis/
│           ├── checkpoints/   # LoRA model checkpoints
│           ├── logs/          # Training logs
│           └── samples/       # Generated validation images
├── src/                       # Source code
│   ├── config/               # Configuration management
│   │   ├── __init__.py
│   │   └── config_manager.py # Dataclass-based config with type safety
│   ├── data/                 # Data pipeline
│   │   ├── __init__.py
│   │   ├── dataset.py        # PyTorch Dataset with medical augmentations
│   │   ├── diffusion_dataset.py # Diffusion training dataset
│   │   └── preprocess.py     # Binary classification data preparation
│   ├── models/               # Model definitions
│   │   ├── __init__.py
│   │   └── classifier.py     # Swin Transformer classifier
│   └── train/                # Training utilities
│       ├── __init__.py
│       └── trainer.py        # Training loop with metrics, logging, checkpointing
├── scripts/                   # Executable scripts
│   ├── filter_and_organize_data.py  # Extract & organize NIH dataset
│   ├── train_classifier.py          # Main training entry point
│   ├── train_diffusion.py           # Diffusion model training
│   ├── test_training_diffusion.py   # Quick diffusion training test
│   ├── create_test_dataset.py       # Create small test dataset
│   ├── test_training.py             # Quick training validation
│   ├── verify_and_fix_images.py     # Verify image availability
│   └── diagnose_missing_images.py   # Debug missing images
├── tests/                     # pytest tests
│   ├── test_config.py        # Configuration management tests
│   └── test_dataloader.py    # Dataset and dataloader tests
├── requirements.txt           # Python dependencies
├── README.md                  # This file
└── TRAINING_TEST.md           # Quick training test documentation
```

## Data Setup

### Option 1: Pre-processed Data (Recommended for Quick Start)

Skip the NIH dataset download and use pre-processed data directly:

#### For Classification Training:
- **Filtered NIH Dataset** (`data/interim/`)
  - Pre-filtered for Hernia, Pneumonia, Fibrosis, Effusion
  - Already organized into train_val/ and test/ directories
  - **Size**: ~14,627 images
  - **Download**: https://drive.google.com/file/d/1xBZDLDPtgVHFpFE79ouLlF4xFp1_oXZv/view?usp=drive_link
  - Extract to: `data/interim/`

#### For Diffusion Training:
- **Balanced Diffusion Dataset** (`data/diffusion_data/`)
  - Balanced across all 15 pathology labels
  - Includes `diffusion_dataset_balanced.csv` metadata
  - **Size**: 10,541 images
  - **Download**: https://drive.google.com/file/d/171Rqd1T97BEnMJ9DPPnxXJ-F85YNJZbR/view?usp=drive_link
  - Extract to: `data/diffusion_data/diffusion_data_balanced/`

### Option 2: Full NIH Dataset (For Custom Filtering)

Download the full NIH Chest X-ray dataset and process it yourself:

1. **`archive.zip`** - NIH Chest X-ray dataset (112,120 PNG images, ~45GB)
   - Download from: [Kaggle NIH Chest X-rays](https://www.kaggle.com/datasets/nih-chest-xrays/data)
   - Place at: `data/raw/archive.zip`

2. **`Data_Entry_2017.csv`** - Original labels file
   - Included in the archive or download separately
   - Place at: `data/raw/Data_Entry_2017.csv`

3. **`train_val_list.txt`** and **`test_list.txt`** - Official train/test split files
   - Defines which images belong to train_val vs test sets
   - Place at: `data/raw/train_val_list.txt` and `data/raw/test_list.txt`

Then run the processing scripts:

```bash
# Extract and organize NIH dataset (creates data/interim/)
python scripts/filter_and_organize_data.py

# Create balanced diffusion dataset (creates data/diffusion_data/)
python scripts/prepare_diffusion_dataset.py
python scripts/balance_diffusion_dataset.py --apply
```

## Quick Start

### 1. Environment Setup

```bash
# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Data Preparation

#### Option A: Using Pre-processed Data
If you downloaded the pre-processed datasets:

```bash
# For classification: Extract filtered data to data/interim/
# For diffusion: Extract balanced data to data/diffusion_data/diffusion_data_balanced/

# Then run binary classification preprocessing
python src/data/preprocess.py --config configs/config.yaml
```

#### Option B: Processing from Raw NIH Dataset
If you downloaded the full NIH dataset:

```bash
# Step 1: Extract and organize NIH dataset (creates data/interim/)
python scripts/filter_and_organize_data.py

# Step 2: Preprocess for binary classification (creates data/processed/)
python src/data/preprocess.py --config configs/config.yaml

# Step 3 (Optional): Create balanced diffusion dataset
python scripts/prepare_diffusion_dataset.py
python scripts/balance_diffusion_dataset.py --apply
```

### 3. Training

#### Classification Training

```bash
# Quick test with small dataset (recommended first)
python scripts/create_test_dataset.py  # Creates 320-image test dataset
python scripts/test_training.py        # Runs 3-epoch test (~5 minutes on CPU)

# Full training
python scripts/train_classifier.py --config configs/config.yaml

# Monitor with TensorBoard
tensorboard --logdir=outputs/<experiment_name>/logs
```

#### Diffusion Model Training

**Prerequisites**: 
- Balanced diffusion dataset should be in: `data/diffusion_data/diffusion_data_balanced/`
- CSV should exist: `data/diffusion_data/diffusion_data_balanced/diffusion_dataset_balanced.csv`
- **If you don't have this**: Either download the pre-processed balanced dataset (Option 1 above) or create it from raw data (see Option 2 data preparation)

```bash
# Quick diffusion test (recommended first)
python scripts/test_training_diffusion.py  # Validates dataset, model imports, and basic setup

# Train Stable Diffusion LoRA model
python scripts/train_diffusion.py --config configs/config_diffusion.yaml

# Monitor training progress
tensorboard --logdir=outputs/diffusion_models/<experiment_name>/logs

# Generate sample images during/after training
python scripts/generate_xrays.py \
    --checkpoint outputs/diffusion_models/<experiment_name>/checkpoints/checkpoint-5000 \
    --prompt "A chest X-ray showing Fibrosis" \
    --num-images 4
```

**Diffusion Training Notes:**
- **Memory Requirements**: Requires ~12GB+ GPU memory for batch_size=1 with gradient accumulation
- **Training Time**: ~2-4 hours per epoch depending on dataset size and GPU
- **LoRA Benefits**: Much faster training and smaller checkpoint files vs full fine-tuning
- **Medical Safety**: No horizontal flips applied to preserve medical image orientation
- **Prompt Format**: Uses template "A chest X-ray showing {labels}" (e.g., "A chest X-ray showing Fibrosis and Cardiomegaly")

### 4. Testing

```bash
# Run all tests
pytest tests/ -v

# Run specific test suite
pytest tests/test_config.py -v
pytest tests/test_dataloader.py -v
```


