# GenMed-Rare

A PyTorch-based medical computer vision project focused on improving rare disease classification through synthetic data augmentation. Uses Stable Diffusion with LoRA fine-tuning to generate synthetic chest X-rays for augmenting rare medical cases, with comprehensive binary classification experiments on the NIH Chest X-ray dataset.

## Project Overview

This project addresses the challenge of medical image classification for rare diseases by synthesizing additional training data using generative models. The pipeline compares classification performance on rare cases (e.g., Fibrosis) vs common cases (e.g., Effusion) with and without synthetic data augmentation from diffusion models.

## Current Implementation Status âœ…

### âœ… Complete Diffusion Pipeline
- **Model**: Stable Diffusion 1.5 with LoRA fine-tuning (PEFT)
- **Dataset**: Balanced chest X-ray dataset (10,541 images, 15 pathology classes)
- **Training**: HuggingFace Diffusers with mixed precision, gradient checkpointing, and comprehensive logging
- **Resume Support**: Full checkpoint resume functionality with automatic latest detection
- **Validation**: Real-time sample generation and FID score tracking
- **Output**: Production-ready LoRA adapters for medical image synthesis

### âœ… Classification Pipeline
- **Dataset**: NIH Chest X-ray (filtered for target pathologies)
- **Task**: Binary classification (configurable rare vs common disease pairs)
- **Model**: Swin Transformer with medical-safe augmentations
- **Training**: PyTorch with TensorBoard logging, early stopping, and robust checkpointing
- **Evaluation**: Comprehensive metrics including precision, recall, F1, and AUC-ROC

### ðŸ”¬ Research Focus
- **Synthetic Augmentation**: Generate rare pathology cases using diffusion models
- **Performance Analysis**: Compare classification metrics with 0%, 10%, 25%, 50% synthetic augmentation
- **Medical Safety**: Orientation-preserving augmentations (no horizontal/vertical flips)
- **Statistical Rigor**: Multi-seed experiments with statistical significance testing

## Repository Structure

```
GenMed-Rare/
â”œâ”€â”€ configs/                    # YAML configuration files
â”‚   â”œâ”€â”€ config.yaml            # Main training configuration (Effusion vs Fibrosis)
â”‚   â”œâ”€â”€ config_diffusion.yaml  # Diffusion model training configuration
â”‚   â””â”€â”€ config_test.yaml       # Quick test configuration (small dataset)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # Raw data (download separately)
â”‚   â”‚   â”œâ”€â”€ archive.zip        # NIH Chest X-ray archive (112,120 images)
â”‚   â”‚   â”œâ”€â”€ Data_Entry_2017.csv # Original labels CSV
â”‚   â”‚   â”œâ”€â”€ train_val_list.txt # Train/val split file
â”‚   â”‚   â””â”€â”€ test_list.txt      # Test split file
â”‚   â”œâ”€â”€ interim/               # Organized data (created by scripts/filter_and_organize_data.py)
â”‚   â”‚   â”œâ”€â”€ train_val/         # Training + validation images organized by label
â”‚   â”‚   â”‚   â”œâ”€â”€ Hernia/
â”‚   â”‚   â”‚   â”œâ”€â”€ Pneumonia/
â”‚   â”‚   â”‚   â”œâ”€â”€ Fibrosis/
â”‚   â”‚   â”‚   â””â”€â”€ Effusion/
â”‚   â”‚   â”œâ”€â”€ test/              # Test images organized by label
â”‚   â”‚   â”‚   â”œâ”€â”€ Hernia/
â”‚   â”‚   â”‚   â”œâ”€â”€ Pneumonia/
â”‚   â”‚   â”‚   â”œâ”€â”€ Fibrosis/
â”‚   â”‚   â”‚   â””â”€â”€ Effusion/
â”‚   â”‚   â””â”€â”€ filtered_data_entry.csv  # Filtered labels CSV
â”‚   â”œâ”€â”€ processed/             # Preprocessed data (created by src/data/preprocess.py)
â”‚   â”‚   â””â”€â”€ effusion_fibrosis/
â”‚   â”‚       â”œâ”€â”€ dataset.csv         # Unified dataset with split column
â”‚   â”‚       â””â”€â”€ dataset_test.csv    # Small test dataset (320 images)
â”‚   â””â”€â”€ diffusion_data/        # Diffusion training data
â”‚       â””â”€â”€ diffusion_data_balanced/  # Balanced dataset for diffusion training
â”‚           â”œâ”€â”€ diffusion_dataset_balanced.csv  # Image metadata
â”‚           â””â”€â”€ *.png          # Chest X-ray images
â”œâ”€â”€ outputs/                   # Training outputs (experiment-specific)
â”‚   â”œâ”€â”€ <experiment_name>/     # e.g., effusion_vs_fibrosis_baseline/ (classification)
â”‚   â”‚   â”œâ”€â”€ checkpoints/       # Model checkpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ best_checkpoint.pth
â”‚   â”‚   â”‚   â””â”€â”€ latest_checkpoint.pth
â”‚   â”‚   â”œâ”€â”€ logs/              # TensorBoard logs
â”‚   â”‚   â””â”€â”€ dataset_summary.csv # Dataset statistics
â”‚   â””â”€â”€ diffusion_models/     # Diffusion training outputs
â”‚       â””â”€â”€ <experiment_name>/ # e.g., sd15_lora_fibrosis/
â”‚           â”œâ”€â”€ checkpoints/   # LoRA model checkpoints
â”‚           â”œâ”€â”€ logs/          # Training logs
â”‚           â””â”€â”€ samples/       # Generated validation images
â”œâ”€â”€ src/                       # Source code
â”‚   â”œâ”€â”€ config/               # Configuration management
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ config_manager.py # Dataclass-based config with type safety
â”‚   â”œâ”€â”€ data/                 # Data pipeline
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dataset.py        # PyTorch Dataset with medical augmentations
â”‚   â”‚   â”œâ”€â”€ diffusion_dataset.py # Diffusion training dataset
â”‚   â”‚   â””â”€â”€ preprocess.py     # Binary classification data preparation
â”‚   â”œâ”€â”€ models/               # Model definitions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ classifier.py     # Swin Transformer classifier
â”‚   â””â”€â”€ train/                # Training utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ trainer.py        # Training loop with metrics, logging, checkpointing
â”œâ”€â”€ scripts/                   # Executable scripts
â”‚   â”œâ”€â”€ filter_and_organize_data.py  # Extract & organize NIH dataset
â”‚   â”œâ”€â”€ train_classifier.py          # Classification training entry point
â”‚   â”œâ”€â”€ train_diffusion.py           # Diffusion model training with resume support
â”‚   â”œâ”€â”€ test_training_diffusion.py   # Diffusion pipeline validation (--no-training flag available)
â”‚   â”œâ”€â”€ test_resume_demo.py          # Checkpoint resume demonstration and verification
â”‚   â”œâ”€â”€ create_test_dataset.py       # Create small test dataset for quick validation
â”‚   â”œâ”€â”€ test_training.py             # Quick classification training test
â”‚   â”œâ”€â”€ verify_and_fix_images.py     # Image integrity verification
â”‚   â””â”€â”€ diagnose_missing_images.py   # Debug missing image files
â”œâ”€â”€ tests/                     # Comprehensive pytest test suite (174 tests)
â”‚   â”œâ”€â”€ test_config.py        # Configuration management tests
â”‚   â”œâ”€â”€ test_dataloader.py    # Dataset and dataloader tests
â”‚   â”œâ”€â”€ test_diffusion_dataset.py    # Diffusion dataset tests
â”‚   â”œâ”€â”€ test_diffusion_training.py   # Diffusion training pipeline tests  
â”‚   â”œâ”€â”€ test_diffusion_resume.py     # Checkpoint resume functionality tests (21 tests)
â”‚   â”œâ”€â”€ test_evaluation.py    # Model evaluation tests
â”‚   â”œâ”€â”€ test_environment.py   # Environment and dependency tests
â”‚   â””â”€â”€ test_trainer_logging.py      # Training and logging tests
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # This file
â””â”€â”€ TRAINING_TEST.md           # Quick training test documentation
```

## Data Setup

### Option 1: Pre-processed Data (Recommended for Quick Start)

Skip the NIH dataset download and use pre-processed data directly:

#### For Classification Training:
- **Filtered NIH Dataset** (`data/interim/`)
  - Pre-filtered for Hernia, Pneumonia, Fibrosis, Effusion
  - Already organized into train_val/ and test/ directories
  - **Size**: ~14,627 images
  - **Download**: https://drive.google.com/file/d/1xBZDLDPtgVHFpFE79ouLlF4xFp1_oXZv/view?usp=drive_link
  - Extract to: `data/interim/`

#### For Diffusion Training:
- **Balanced Diffusion Dataset** (`data/diffusion_data/`)
  - Balanced across all 15 pathology labels
  - Includes `diffusion_dataset_balanced.csv` metadata
  - **Size**: 10,541 images
  - **Download**: https://drive.google.com/file/d/171Rqd1T97BEnMJ9DPPnxXJ-F85YNJZbR/view?usp=drive_link
  - Extract to: `data/diffusion_data/diffusion_data_balanced/`

### Option 2: Full NIH Dataset (For Custom Filtering)

Download the full NIH Chest X-ray dataset and process it yourself:

1. **`archive.zip`** - NIH Chest X-ray dataset (112,120 PNG images, ~45GB)
   - Download from: [Kaggle NIH Chest X-rays](https://www.kaggle.com/datasets/nih-chest-xrays/data)
   - Place at: `data/raw/archive.zip`

2. **`Data_Entry_2017.csv`** - Original labels file
   - Included in the archive or download separately
   - Place at: `data/raw/Data_Entry_2017.csv`

3. **`train_val_list.txt`** and **`test_list.txt`** - Official train/test split files
   - Defines which images belong to train_val vs test sets
   - Place at: `data/raw/train_val_list.txt` and `data/raw/test_list.txt`

Then run the processing scripts:

```bash
# Extract and organize NIH dataset (creates data/interim/)
python scripts/filter_and_organize_data.py

# Create balanced diffusion dataset (creates data/diffusion_data/)
python scripts/prepare_diffusion_dataset.py
python scripts/balance_diffusion_dataset.py --apply
```

## Quick Start

### 1. Environment Setup

```bash
# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Data Preparation

#### Option A: Using Pre-processed Data
If you downloaded the pre-processed datasets:

```bash
# For classification: Extract filtered data to data/interim/
# For diffusion: Extract balanced data to data/diffusion_data/diffusion_data_balanced/

# Then run binary classification preprocessing
python src/data/preprocess.py --config configs/config.yaml
```

#### Option B: Processing from Raw NIH Dataset
If you downloaded the full NIH dataset:

```bash
# Step 1: Extract and organize NIH dataset (creates data/interim/)
python scripts/filter_and_organize_data.py

# Step 2: Preprocess for binary classification (creates data/processed/)
python src/data/preprocess.py --config configs/config.yaml

# Step 3 (Optional): Create balanced diffusion dataset
python scripts/prepare_diffusion_dataset.py
python scripts/balance_diffusion_dataset.py --apply
```

### 3. Training

#### Classification Training

```bash
# Quick test with small dataset (recommended first)
python scripts/create_test_dataset.py  # Creates 320-image test dataset
python scripts/test_training.py        # Runs 3-epoch test (~5 minutes on CPU)

# Full training
python scripts/train_classifier.py --config configs/config.yaml

# Monitor with TensorBoard
tensorboard --logdir=outputs/<experiment_name>/logs
```

#### Diffusion Model Training

**Prerequisites**: 
- Balanced diffusion dataset in: `data/diffusion_data/diffusion_data_balanced/`
- CSV metadata: `data/diffusion_data/diffusion_data_balanced/diffusion_dataset_balanced.csv`
- **GPU Requirements**: 8GB+ VRAM recommended (RTX 2070 or better)

```bash
# Quick diffusion pipeline validation (recommended first)
python scripts/test_training_diffusion.py --no-training  # Validates setup without training

# Train Stable Diffusion LoRA model from scratch
python scripts/train_diffusion.py --config configs/config_diffusion.yaml

# Resume training from latest checkpoint (if available)
python scripts/train_diffusion.py --config configs/config_diffusion.yaml --resume-latest

# Resume from specific checkpoint
python scripts/train_diffusion.py --config configs/config_diffusion.yaml \
    --resume outputs/diffusion_models/sd15_lora_fibrosis/checkpoints/checkpoint-step-5000

# List available checkpoints and verify integrity
python scripts/test_resume_demo.py

# Monitor training progress
tensorboard --logdir=outputs/diffusion_models/sd15_lora_fibrosis/logs
```

**Checkpoint Resume Features:**
- âœ… **Automatic Latest Detection**: `--resume-latest` finds and resumes from most recent checkpoint
- âœ… **Manual Selection**: `--resume path/to/checkpoint` resumes from specific checkpoint  
- âœ… **Step Tracking**: Properly continues from exact training step (not just epoch)
- âœ… **LoRA Loading**: Correctly loads PEFT adapter weights and training state
- âœ… **Validation**: Comprehensive checkpoint integrity verification
- âœ… **Error Handling**: Robust handling of corrupted or missing checkpoints

**Current Checkpoint Status:**
- **Latest Available**: Step 7,000 (if previous training exists)
- **Total Checkpoints**: 16 valid checkpoints available for resume
- **Checkpoint Types**: Both step-based and epoch-based supported

**Training Configuration:**
- **Model**: Stable Diffusion 1.5 + LoRA adapters (16 rank, 32 alpha)
- **Optimization**: AdamW with cosine annealing, gradient accumulation
- **Memory**: Mixed precision (fp16), gradient checkpointing for efficiency  
- **Validation**: Real-time sample generation, FID score tracking
- **Safety**: Medical-appropriate data augmentations (no orientation flips)

### 4. Testing & Validation

```bash
# Run comprehensive test suite (174 tests)
pytest tests/ -v

# Test specific components
pytest tests/test_diffusion_resume.py -v     # Checkpoint resume functionality (21 tests)
pytest tests/test_diffusion_training.py -v   # Diffusion training pipeline (14 tests) 
pytest tests/test_diffusion_dataset.py -v    # Diffusion dataset (17 tests)
pytest tests/test_config.py -v               # Configuration management
pytest tests/test_dataloader.py -v           # Dataset and dataloader functionality
pytest tests/test_evaluation.py -v           # Model evaluation metrics

# Quick validation scripts
python scripts/test_training_diffusion.py --no-training  # Diffusion setup validation
python scripts/test_training.py                          # Classification training test
python scripts/test_resume_demo.py                       # Checkpoint resume demo
```

## Key Features

### ðŸš€ Production-Ready Diffusion Training
- **Stable Diffusion 1.5** with LoRA fine-tuning for efficient medical image generation
- **Checkpoint Resume**: Robust training continuation from any checkpoint
- **Memory Optimized**: Mixed precision, gradient checkpointing, gradient accumulation
- **Medical Safety**: Orientation-preserving augmentations for medical imaging standards
- **Comprehensive Logging**: TensorBoard integration with loss tracking and sample generation

### ðŸ“Š Advanced Classification Pipeline  
- **Swin Transformer**: State-of-the-art vision transformer for medical image classification
- **Medical Augmentations**: Rotation, brightness/contrast, Gaussian noise (no harmful flips)
- **Multi-Class Support**: Configurable binary classification for any rare vs common disease pair
- **Robust Training**: Early stopping, learning rate scheduling, comprehensive metrics

### ðŸ”¬ Research Infrastructure
- **Experiment Management**: Auto-generated experiment names with timestamp and configuration
- **Reproducibility**: Deterministic training with configurable random seeds
- **Statistical Analysis**: Multi-seed experiment support for rigorous evaluation
- **Data Integrity**: Comprehensive validation and error checking throughout pipeline

### âœ… Quality Assurance
- **174 Test Cases**: Comprehensive pytest coverage for all components
- **CI/CD Ready**: Automated testing for model training, data loading, and configuration
- **Error Handling**: Robust exception handling with informative error messages
- **Documentation**: Extensive inline documentation and configuration examples

## Research Applications

This codebase supports several research directions in medical AI:

1. **Synthetic Data Augmentation**: Quantify improvement from generative model augmentation
2. **Rare Disease Classification**: Address class imbalance through targeted data synthesis  
3. **Medical Image Quality**: Evaluate synthetic vs real medical image utility
4. **Transfer Learning**: Study domain adaptation between synthetic and real medical images
5. **Fairness & Bias**: Analyze model performance across different patient demographics

## Performance Benchmarks

### Classification Baseline Results
- **Effusion vs Fibrosis**: 92.5% accuracy, 0.89 F1-score (baseline without augmentation)
- **Training Time**: ~45 minutes for full training on RTX 2070 with Max-Q Design
- **Memory Usage**: ~6GB GPU memory for batch_size=32

### Diffusion Training Performance  
- **Training Speed**: ~3-4 hours per epoch (10,541 images) on RTX 2070 with Max-Q Design
- **Memory Usage**: ~7.5GB GPU memory with mixed precision and gradient checkpointing
- **Checkpoint Size**: ~16MB per LoRA checkpoint (vs ~5GB for full model fine-tuning)
- **Generation Speed**: ~2-3 seconds per 512Ã—512 image

## Dependencies

Core requirements (see `requirements.txt` for complete list):

```python
# Core ML Libraries
torch>=2.0.0
torchvision>=0.15.0
transformers>=4.35.0
diffusers>=0.21.0
accelerate>=0.24.0
peft>=0.6.0

# Data & Visualization  
pandas>=2.0.0
numpy>=1.24.0
pillow>=10.0.0
matplotlib>=3.7.0
seaborn>=0.12.0

# Training & Logging
tensorboard>=2.14.0
tqdm>=4.65.0
pyyaml>=6.0.0
timm>=0.9.0

# Testing & Validation
pytest>=7.4.0
scikit-learn>=1.3.0
scikit-image>=0.21.0
```

## Contributing

1. **Code Quality**: Follow PEP 8, add type hints, maintain test coverage
2. **Medical Safety**: Preserve image orientation, validate augmentation appropriateness
3. **Testing**: Add tests for new features, maintain 90%+ coverage
4. **Documentation**: Update README and docstrings for new components
5. **Configuration**: Use YAML configs for new experiments, avoid hardcoded parameters

## Citation

If you use this codebase in your research, please cite:

```bibtex
@article{genmed_rare_2025,
  title={Improving Rare Disease Classification through Synthetic Data Augmentation with Stable Diffusion},
  author={Your Name},
  journal={Medical Image Analysis},
  year={2025},
  note={GenMed-Rare: A PyTorch framework for medical image synthesis and classification}
}
```

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- **NIH Clinical Center**: For providing the Chest X-ray dataset
- **HuggingFace**: For the diffusers library and model hosting  
- **PyTorch Team**: For the deep learning framework
- **Medical AI Community**: For advancing responsible AI in healthcare


