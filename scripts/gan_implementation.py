# -*- coding: utf-8 -*-
"""GAN_implementation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1emZRK6V76ecXupj-E-nCrv6tVGjUKvqy
"""

import os
import sys
from pathlib import Path
import random
from typing import List, Tuple
from collections import defaultdict, deque

import numpy as np
from PIL import Image

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, ConcatDataset, Subset

import torchvision.transforms as T
import torchvision.models as models
from torchvision.utils import save_image

from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.manifold import TSNE

import matplotlib.pyplot as plt

# Colab-specific imports
from google.colab import drive, files
import shutil

# ============================================================
# Mount Google Drive (for code + data)
# ============================================================
print("Mounting Google Drive...")
drive.mount("/content/drive")

# ============================================================
# Config / paths
# ============================================================

# Debug flag (keep False for full runs)
DEBUG_MODE = False
DEBUG_MAX_PER_CLASS = 20

# Root of your project on Google Drive
DRIVE_ROOT = Path("/content/drive/MyDrive/CV_Project")

# Code/data roots
ROOT_DIR = DRIVE_ROOT
DATA_ROOT = DRIVE_ROOT / "data" / "interim"
GAN_RARE_ROOT = DRIVE_ROOT / "pure_class_folders"

# Outputs go ONLY to Colab local disk (NOT Drive) to avoid quota issues
LOCAL_OUT = Path("/content/CV_Project_outputs")
GAN_SYN_ROOT = LOCAL_OUT / "gan_synthetic"
CHECKPOINT_DIR = LOCAL_OUT / "checkpoints"

# Create local output dirs
GAN_SYN_ROOT.mkdir(parents=True, exist_ok=True)
CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)

# Device + seeds
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
if DEVICE == "cuda":
    torch.cuda.manual_seed_all(SEED)

print("Device:", DEVICE)
print("DATA_ROOT:", DATA_ROOT)
print("GAN_RARE_ROOT (pure labels):", GAN_RARE_ROOT)
print("Synthetic output (local in Colab):", GAN_SYN_ROOT)
print("Checkpoints (local in Colab):", CHECKPOINT_DIR)

# Classes
ALL_CLASSES = ["Fibrosis", "Pneumonia", "Effusion"]
RARE_CLASSES = ["Fibrosis", "Pneumonia"]
COMMON_CLASSES = ["Effusion"]

# For GAN training we use the "pure_class_folders" names (lowercase)
GAN_RARE_CLASS_MAP = {
    "fibrosis": "Fibrosis",
    "pneumonia": "Pneumonia",
}

CLASS_TO_IDX = {c: i for i, c in enumerate(ALL_CLASSES)}

# NOTE: Swin-T was pretrained on 224x224, but for this project
# we keep 128x128 to match the current GAN architecture and GPU budget.
IMG_SIZE = 128
BATCH_SIZE = 32

# Hyperparameters (tuned to avoid GAN collapse and reduce noise)
if DEBUG_MODE:
    CGAN_EPOCHS = 2
    SWIN_EPOCHS_BASELINE = 1
    SWIN_EPOCHS_ABLATION = 1
    GAN_SAMPLES_PER_CLASS = 50
else:
    # Old: 40 epochs (GAN collapsed), New: 25 + early stopping
    CGAN_EPOCHS = 25
    SWIN_EPOCHS_BASELINE = 10
    SWIN_EPOCHS_ABLATION = 8
    # Old: 800 per class (too much noisy synthetic), New: 400
    GAN_SAMPLES_PER_CLASS = 400


# ============================================================
# Datasets
# ============================================================

class PathLabelDataset(Dataset):
    """Generic dataset from (path, label) tuples."""
    def __init__(self, samples: List[Tuple[Path, int]], transform=None):
        self.samples = samples
        self.transform = transform

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        path, label = self.samples[idx]
        img = Image.open(path).convert("RGB")
        if self.transform is not None:
            img = self.transform(img)
        return img, label


class TestFolderDataset(Dataset):
    """Test set from data/interim/test/<class> folders."""
    def __init__(self, root: Path, classes: List[str], transform=None):
        self.samples = []
        self.transform = transform
        base = root / "test"

        for cls in classes:
            cls_dir = base / cls
            if not cls_dir.exists():
                print(f"Warning: missing test folder {cls_dir}")
                continue
            for p in cls_dir.glob("*.png"):
                self.samples.append((p, CLASS_TO_IDX[cls]))

        print(f"Test set: {len(self.samples)} images")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        path, label = self.samples[idx]
        img = Image.open(path).convert("RGB")
        if self.transform is not None:
            img = self.transform(img)
        return img, label


class SyntheticDataset(Dataset):
    """Dataset for GAN-generated synthetic images (per rare class)."""
    def __init__(self, root: Path, classes: List[str], transform=None):
        self.samples = []
        self.transform = transform

        for cls in classes:
            cls_dir = root / cls
            if not cls_dir.exists():
                continue
            for p in cls_dir.glob("*.png"):
                self.samples.append((p, CLASS_TO_IDX[cls]))

        print(f"Synthetic dataset: {len(self.samples)} images from {root}")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        path, label = self.samples[idx]
        img = Image.open(path).convert("RGB")
        if self.transform is not None:
            img = self.transform(img)
        return img, label


def scan_trainval(root: Path, classes: List[str]):
    """Scan data/interim/train_val/<class> for classifier training."""
    samples = []
    base = root / "train_val"
    for cls in classes:
        cls_dir = base / cls
        if not cls_dir.exists():
            print(f"Warning: missing folder {cls_dir}")
            continue
        for p in cls_dir.glob("*.png"):
            samples.append((p, CLASS_TO_IDX[cls]))
    print(f"Scanned train_val: {len(samples)} images")
    return samples


def get_transforms(train=True):
    if train:
        return T.Compose([
            T.Resize((IMG_SIZE, IMG_SIZE)),
            T.RandomHorizontalFlip(),
            T.RandomRotation(10),
            T.ColorJitter(brightness=0.1, contrast=0.1),
            T.ToTensor(),
            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
        ])
    else:
        return T.Compose([
            T.Resize((IMG_SIZE, IMG_SIZE)),
            T.ToTensor(),
            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
        ])


def stratified_split(samples, val_ratio=0.2):
    """Stratified train/val split over ALL_CLASSES."""
    labels = np.array([lbl for _, lbl in samples])
    indices = np.arange(len(samples))

    splitter = StratifiedShuffleSplit(
        n_splits=1,
        test_size=val_ratio,
        random_state=SEED
    )
    train_idx, val_idx = next(splitter.split(indices, labels))

    train_samples = [samples[i] for i in train_idx]
    val_samples = [samples[i] for i in val_idx]

    print(f"Split: {len(train_samples)} train, {len(val_samples)} val")
    return train_samples, val_samples


class RareForGAN(Dataset):
    """
    Dataset for GAN training using *pure* single-label images from:
    CV_Project/pure_class_folders/{fibrosis, pneumonia}.
    """
    def __init__(self, root: Path, transform=None):
        self.samples = []
        self.transform = transform

        # local labels: 0=fibrosis, 1=pneumonia
        local_class_to_idx = {name: i for i, name in enumerate(GAN_RARE_CLASS_MAP.keys())}

        for folder_name in GAN_RARE_CLASS_MAP.keys():
            cls_dir = root / folder_name
            if not cls_dir.exists():
                print(f"Warning: missing GAN folder {cls_dir}")
                continue
            paths = list(cls_dir.glob("*.png"))
            random.shuffle(paths)
            for p in paths:
                self.samples.append((p, local_class_to_idx[folder_name]))

        random.shuffle(self.samples)
        print(f"cGAN dataset (pure): {len(self.samples)} images "
              f"from {list(GAN_RARE_CLASS_MAP.keys())}")
        self.num_classes = len(local_class_to_idx)
        self.local_class_to_idx = local_class_to_idx

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        path, local_label = self.samples[idx]
        img = Image.open(path).convert("RGB")
        if self.transform is not None:
            img = self.transform(img)
        return img, local_label


# ============================================================
# GAN Models
# ============================================================

class Generator(nn.Module):
    """Conditional GAN generator for rare classes."""
    def __init__(self, z_dim=100, num_classes=2, img_ch=3, feat=64):
        super().__init__()
        self.embed = nn.Embedding(num_classes, z_dim)

        self.net = nn.Sequential(
            self._block(z_dim * 2, feat * 8, 4, 1, 0),  # 1x1 → 4x4
            self._block(feat * 8, feat * 4, 4, 2, 1),   # → 8x8
            self._block(feat * 4, feat * 2, 4, 2, 1),   # → 16x16
            self._block(feat * 2, feat, 4, 2, 1),       # → 32x32
            nn.ConvTranspose2d(feat, feat // 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(feat // 2),
            nn.ReLU(True),                              # → 64x64
            nn.ConvTranspose2d(feat // 2, img_ch, 4, 2, 1),
            nn.Tanh(),                                  # → 128x128
        )

    def _block(self, in_ch, out_ch, k, s, p):
        return nn.Sequential(
            nn.ConvTranspose2d(in_ch, out_ch, k, s, p, bias=False),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(True),
        )

    def forward(self, z, labels):
        emb = self.embed(labels).unsqueeze(2).unsqueeze(3)
        x = torch.cat([z, emb], dim=1)
        return self.net(x)


class Discriminator(nn.Module):
    """Discriminator with real/fake head + class head for GAN."""
    def __init__(self, num_classes=2, img_ch=3, feat=64):
        super().__init__()
        self.net = nn.Sequential(
            self._block(img_ch, feat, 4, 2, 1, first=True),
            self._block(feat, feat * 2, 4, 2, 1),
            self._block(feat * 2, feat * 4, 4, 2, 1),
            self._block(feat * 4, feat * 8, 4, 2, 1),
        )
        self.adv_head = nn.Sequential(
            nn.Conv2d(feat * 8, 1, 4, 1, 0),
            nn.Flatten()
        )
        self.cls_head = nn.Sequential(
            nn.Conv2d(feat * 8, num_classes, 4, 1, 0),
            nn.Flatten()
        )

    def _block(self, in_ch, out_ch, k, s, p, first=False):
        layers = [nn.Conv2d(in_ch, out_ch, k, s, p, bias=False)]
        if not first:
            layers.append(nn.BatchNorm2d(out_ch))
        layers.append(nn.LeakyReLU(0.2, inplace=True))
        return nn.Sequential(*layers)

    def forward(self, x):
        f = self.net(x)
        adv = self.adv_head(f)
        cls = self.cls_head(f)
        return adv, cls


# ============================================================
# GAN training + generation (with early stopping & smoothing)
# ============================================================

def train_cgan():
    """Train conditional GAN on pure fibrosis/pneumonia with early stopping."""
    print("\n" + "="*60)
    print("Training cGAN on pure_class_folders")
    print("="*60)

    gan_transform = T.Compose([
        T.Resize((IMG_SIZE, IMG_SIZE)),
        T.CenterCrop(IMG_SIZE),
        T.ToTensor(),
        T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),
    ])

    ds = RareForGAN(GAN_RARE_ROOT, transform=gan_transform)
    if len(ds) == 0:
        print("No pure rare samples found, skipping GAN training.")
        return None, 0

    loader = DataLoader(ds, batch_size=32, shuffle=True, drop_last=True)

    z_dim = 100
    G = Generator(z_dim=z_dim, num_classes=ds.num_classes).to(DEVICE)
    D = Discriminator(num_classes=ds.num_classes).to(DEVICE)

    bce = nn.BCEWithLogitsLoss()
    ce = nn.CrossEntropyLoss()
    opt_G = optim.Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))
    opt_D = optim.Adam(D.parameters(), lr=2e-4, betas=(0.5, 0.999))

    g_losses, d_losses = [], []
    recent_d = deque(maxlen=5)

    for epoch in range(1, CGAN_EPOCHS + 1):
        G.train()
        D.train()
        epoch_g_loss = 0.0
        epoch_d_loss = 0.0
        n_batches = 0

        for real_imgs, labels_local in loader:
            real_imgs = real_imgs.to(DEVICE)
            labels_local = labels_local.to(DEVICE)
            batch_size = real_imgs.size(0)

            # -----------------------
            # Train D
            # -----------------------
            z = torch.randn(batch_size, z_dim, 1, 1, device=DEVICE)
            fake_labels = torch.randint(0, ds.num_classes, (batch_size,), device=DEVICE)
            fake_imgs = G(z, fake_labels)

            D_real_adv, D_real_cls = D(real_imgs)
            D_fake_adv, D_fake_cls = D(fake_imgs.detach())

            # Label smoothing: Real targets = 0.9 instead of 1.0
            real_targets = torch.full_like(D_real_adv, 0.9)
            fake_targets = torch.zeros_like(D_fake_adv)

            adv_real = bce(D_real_adv, real_targets)
            adv_fake = bce(D_fake_adv, fake_targets)
            adv_loss = adv_real + adv_fake

            cls_loss_real = ce(D_real_cls, labels_local)

            D_loss = adv_loss + cls_loss_real
            opt_D.zero_grad()
            D_loss.backward()
            torch.nn.utils.clip_grad_norm_(D.parameters(), 1.0)
            opt_D.step()

            # -----------------------
            # Train G
            # -----------------------
            z = torch.randn(batch_size, z_dim, 1, 1, device=DEVICE)
            gen_labels = torch.randint(0, ds.num_classes, (batch_size,), device=DEVICE)
            gen_imgs = G(z, gen_labels)
            D_fake_adv, D_fake_cls = D(gen_imgs)

            # Generator wants D_fake_adv to think they're real (target=0.9)
            adv_loss_G = bce(D_fake_adv, real_targets)
            cls_loss_G = ce(D_fake_cls, gen_labels)
            G_loss = adv_loss_G + cls_loss_G

            opt_G.zero_grad()
            G_loss.backward()
            torch.nn.utils.clip_grad_norm_(G.parameters(), 1.0)
            opt_G.step()

            epoch_g_loss += G_loss.item()
            epoch_d_loss += D_loss.item()
            n_batches += 1

        epoch_g_loss /= max(n_batches, 1)
        epoch_d_loss /= max(n_batches, 1)
        g_losses.append(epoch_g_loss)
        d_losses.append(epoch_d_loss)
        recent_d.append(epoch_d_loss)

        print(f"Epoch {epoch}/{CGAN_EPOCHS} - "
              f"D loss: {epoch_d_loss:.4f}, G loss: {epoch_g_loss:.4f}")

        # Early stopping: if D is too perfect for too long, stop
        if len(recent_d) == recent_d.maxlen and np.mean(recent_d) < 0.15:
            print(f"Early stopping cGAN at epoch {epoch} "
                  f"(mean D loss over last {recent_d.maxlen} epochs < 0.15).")
            break

    # Loss curves
    plt.figure(figsize=(8, 5))
    plt.plot(g_losses, label="Generator")
    plt.plot(d_losses, label="Discriminator")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.title("cGAN Training Loss (pure fibrosis/pneumonia)")
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()

    torch.save(G.state_dict(), CHECKPOINT_DIR / "cgan_generator.pth")
    return G, ds.num_classes


def generate_gan_synthetic(G, num_gan_classes: int):
    """Generate GAN images for rare classifier labels (Fibrosis, Pneumonia)."""
    if G is None or num_gan_classes == 0:
        print("No trained generator, skipping synthetic generation.")
        return

    print("\n" + "="*60)
    print("Generating GAN synthetic images for Fibrosis / Pneumonia")
    print("="*60)

    G.eval()
    z_dim = 100

    # local 0 -> fibrosis, 1 -> pneumonia (by construction)
    local_to_global = {
        0: "Fibrosis",
        1: "Pneumonia",
    }

    with torch.no_grad():
        for local_idx in range(num_gan_classes):
            global_name = local_to_global[local_idx]
            out_dir = GAN_SYN_ROOT / global_name
            out_dir.mkdir(parents=True, exist_ok=True)

            n_left = GAN_SAMPLES_PER_CLASS
            counter = 0

            while n_left > 0:
                bsz = min(32, n_left)
                z = torch.randn(bsz, z_dim, 1, 1, device=DEVICE)
                labels = torch.full((bsz,), local_idx, device=DEVICE, dtype=torch.long)
                fake_batch = G(z, labels)
                fake_batch = (fake_batch * 0.5) + 0.5  # [-1,1] → [0,1]

                for i in range(bsz):
                    save_path = out_dir / f"syn_{global_name}_{counter:05d}.png"
                    save_image(fake_batch[i], save_path)
                    counter += 1

                n_left -= bsz

            # Preview grid (for report figures)
            z = torch.randn(20, z_dim, 1, 1, device=DEVICE)
            labels = torch.full((20,), local_idx, device=DEVICE, dtype=torch.long)
            preview = G(z, labels)
            preview = (preview * 0.5) + 0.5
            save_image(preview, GAN_SYN_ROOT / f"preview_{global_name}.png", nrow=5)

            print(f"Generated {counter} images for {global_name}")


# ============================================================
# Classifier + losses
# ============================================================

def create_backbone(num_classes):
    """Swin Transformer (preferred), fallback to ResNet18."""
    try:
        from torchvision.models import swin_t, Swin_T_Weights
        model = swin_t(weights=Swin_T_Weights.IMAGENET1K_V1)
        in_features = model.head.in_features
        model.head = nn.Linear(in_features, num_classes)
        print("Using Swin Transformer.")
    except Exception as e:
        print(f"Swin not available ({e}), falling back to ResNet18.")
        model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
        in_features = model.fc.in_features
        model.fc = nn.Linear(in_features, num_classes)
    return model


def compute_class_weights(samples):
    """
    Softer, tempered inverse-frequency class weights.
    - Old: very aggressive reweighting (Effusion ~0.11) → unstable training
    - New:
      * Start from inverse frequency
      * Normalize to mean = 1
      * Raise to power alpha < 1 to temper
      * Clamp to [0.5, 2.0]
    """
    labels = [lbl for _, lbl in samples]
    counts = np.bincount(labels, minlength=len(ALL_CLASSES)).astype(float)

    inv_freq = 1.0 / np.maximum(counts, 1.0)
    inv_freq = inv_freq / inv_freq.mean()  # mean ≈ 1

    alpha = 0.7  # tempered
    weights = inv_freq ** alpha
    weights = np.clip(weights, 0.5, 2.0)

    w_tensor = torch.tensor(weights, dtype=torch.float32, device=DEVICE)

    print("Class distribution (train_val subset used):")
    for i, cls in enumerate(ALL_CLASSES):
        print(f"  {cls}: {int(counts[i])} samples, weight: {weights[i]:.3f}")

    return w_tensor


def train_classifier(train_ds, val_ds, name, num_epochs,
                     loss_type="ce", class_weights=None):
    """Train Swin classifier with CE / weighted CE."""
    print("\n" + "="*60)
    print(f"Training classifier: {name}")
    print("="*60)

    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)

    model = create_backbone(num_classes=len(ALL_CLASSES)).to(DEVICE)

    if loss_type == "weighted" and class_weights is not None:
        criterion = nn.CrossEntropyLoss(weight=class_weights)
        print("Loss: weighted cross-entropy.")
    else:
        criterion = nn.CrossEntropyLoss()
        print("Loss: standard cross-entropy.")

    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)

    train_losses, val_losses = [], []
    train_accs, val_accs = [], []
    best_val_acc = 0.0

    for epoch in range(1, num_epochs + 1):
        # Train
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0

        for imgs, labels in train_loader:
            imgs = imgs.to(DEVICE)
            labels = labels.to(DEVICE)

            optimizer.zero_grad()
            outputs = model(imgs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * imgs.size(0)
            preds = outputs.argmax(dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

        train_loss = running_loss / max(total, 1)
        train_acc = correct / max(total, 1)

        # Val
        model.eval()
        v_loss = 0.0
        v_corr = 0
        v_tot = 0
        with torch.no_grad():
            for imgs, labels in val_loader:
                imgs = imgs.to(DEVICE)
                labels = labels.to(DEVICE)
                outputs = model(imgs)
                loss = criterion(outputs, labels)
                v_loss += loss.item() * imgs.size(0)
                preds = outputs.argmax(dim=1)
                v_corr += (preds == labels).sum().item()
                v_tot += labels.size(0)

        val_loss = v_loss / max(v_tot, 1)
        val_acc = v_corr / max(v_tot, 1)

        train_losses.append(train_loss)
        val_losses.append(val_loss)
        train_accs.append(train_acc)
        val_accs.append(val_acc)

        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save(
                model.state_dict(),
                CHECKPOINT_DIR / f"{name.replace(' ', '_')}_best.pth"
            )

        print(f"Epoch {epoch}/{num_epochs} - "
              f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | "
              f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")

        scheduler.step()

    # Plots
    epochs = range(1, num_epochs + 1)
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

    ax1.plot(epochs, train_losses, label="Train", marker='o')
    ax1.plot(epochs, val_losses, label="Val", marker='s')
    ax1.set_xlabel("Epoch")
    ax1.set_ylabel("Loss")
    ax1.set_title(f"{name} - Loss")
    ax1.legend()
    ax1.grid(alpha=0.3)

    ax2.plot(epochs, train_accs, label="Train", marker='o')
    ax2.plot(epochs, val_accs, label="Val", marker='s')
    ax2.set_xlabel("Epoch")
    ax2.set_ylabel("Accuracy")
    ax2.set_title(f"{name} - Accuracy")
    ax2.legend()
    ax2.grid(alpha=0.3)

    plt.tight_layout()
    plt.show()

    torch.save(
        model.state_dict(),
        CHECKPOINT_DIR / f"{name.replace(' ', '_')}_final.pth"
    )
    return model


def eval_on_test(model, name):
    """Evaluate on data/interim/test/*."""
    print("\n" + "="*60)
    print(f"Test Evaluation: {name}")
    print("="*60)

    test_ds = TestFolderDataset(
        DATA_ROOT,
        ALL_CLASSES,
        transform=get_transforms(train=False)
    )
    if len(test_ds) == 0:
        print("No test data found.")
        return

    loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)
    all_preds = []
    all_labels = []

    model.eval()
    with torch.no_grad():
        for imgs, labels in loader:
            imgs = imgs.to(DEVICE)
            labels = labels.to(DEVICE)
            outputs = model(imgs)
            preds = outputs.argmax(dim=1)
            all_preds.append(preds.cpu().numpy())
            all_labels.append(labels.cpu().numpy())

    all_preds = np.concatenate(all_preds, axis=0)
    all_labels = np.concatenate(all_labels, axis=0)

    print("\nClassification Report:")
    print(classification_report(
        all_labels,
        all_preds,
        target_names=ALL_CLASSES,
        digits=4
    ))

    cm = confusion_matrix(all_labels, all_preds)
    fig, ax = plt.subplots(figsize=(6, 5))
    im = ax.imshow(cm, cmap="Blues", interpolation='nearest')

    ax.set_xticks(np.arange(len(ALL_CLASSES)))
    ax.set_yticks(np.arange(len(ALL_CLASSES)))
    ax.set_xticklabels(ALL_CLASSES)
    ax.set_yticklabels(ALL_CLASSES)
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right")

    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(
                j, i, cm[i, j],
                ha="center", va="center",
                color="white" if cm[i, j] > cm.max() / 2 else "black",
                fontsize=12, fontweight='bold'
            )

    ax.set_xlabel("Predicted Label", fontsize=11)
    ax.set_ylabel("True Label", fontsize=11)
    ax.set_title(f"Confusion Matrix - {name}", fontsize=12, fontweight='bold')
    plt.colorbar(im, ax=ax)
    plt.tight_layout()
    plt.show()


# ============================================================
# GAN ablation + t-SNE
# ============================================================

def build_gan_ablation_dataset(train_samples, val_samples, factor):
    """
    real + subset of GAN synthetic data (factor × rare count).
    In the final report we keep a single, conservative GAN regime.
    """
    train_real = PathLabelDataset(train_samples, transform=get_transforms(train=True))
    val_real = PathLabelDataset(val_samples, transform=get_transforms(train=False))

    rare_ids = [CLASS_TO_IDX[c] for c in RARE_CLASSES]
    real_rare_count = sum(1 for _, lbl in train_samples if lbl in rare_ids)
    target_syn = max(int(factor * real_rare_count), 1)

    print(f"\nGAN Ablation ({factor}x):")
    print(f"  Real rare samples: {real_rare_count}")
    print(f"  Target synthetic: {target_syn}")

    syn_ds = SyntheticDataset(GAN_SYN_ROOT, RARE_CLASSES, transform=get_transforms(train=True))

    if len(syn_ds) == 0:
        print("  No synthetic data found, using real only.")
        return train_real, val_real

    idxs = list(range(len(syn_ds)))
    random.shuffle(idxs)
    idxs = idxs[:min(target_syn, len(idxs))]

    print(f"  Using {len(idxs)} synthetic images.")
    syn_subset = Subset(syn_ds, idxs)
    train_combined = ConcatDataset([train_real, syn_subset])

    return train_combined, val_real


class RareRealDataset(Dataset):
    """Real rare samples (Fibrosis/Pneumonia) from train_val for t-SNE."""
    def __init__(self, root: Path, transform=None, max_per_class=300):
        self.samples = []
        self.transform = transform
        base = root / "train_val"

        for cls in RARE_CLASSES:
            cls_dir = base / cls
            if not cls_dir.exists():
                continue
            paths = list(cls_dir.glob("*.png"))
            random.shuffle(paths)
            paths = paths[:max_per_class]
            self.samples.extend((p, CLASS_TO_IDX[cls]) for p in paths)

        print(f"Real rare dataset for t-SNE: {len(self.samples)} images")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        path, label = self.samples[idx]
        img = Image.open(path).convert("RGB")
        if self.transform is not None:
            img = self.transform(img)
        return img, label


def build_feature_extractor():
    """ResNet50 backbone, global avg-pooled to 2048-d features."""
    base = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1).to(DEVICE)
    modules = list(base.children())[:-1]

    class FeatureExtractor(nn.Module):
        def __init__(self, net):
            super().__init__()
            self.net = net

        def forward(self, x):
            with torch.no_grad():
                f = self.net(x)
                return f.view(f.size(0), -1)

    return FeatureExtractor(nn.Sequential(*modules)).to(DEVICE)


def run_latent_tsne():
    """t-SNE: real rare vs GAN synthetic in ResNet50 feature space."""
    print("\n" + "="*60)
    print("t-SNE: Real vs GAN synthetic (rare classes)")
    print("="*60)

    transform = get_transforms(train=False)
    max_samples = 300 if not DEBUG_MODE else 50

    real_ds = RareRealDataset(DATA_ROOT, transform=transform, max_per_class=max_samples)
    gan_ds = SyntheticDataset(GAN_SYN_ROOT, RARE_CLASSES, transform=transform)

    extractor = build_feature_extractor()

    def collect_features(ds, max_samples):
        if len(ds) == 0:
            return np.zeros((0, 2048)), np.zeros((0,))
        loader = DataLoader(ds, batch_size=32, shuffle=True)
        feats_list, labels_list = [], []
        total = 0

        with torch.no_grad():
            for imgs, labels in loader:
                imgs = imgs.to(DEVICE)
                feats = extractor(imgs)
                feats_list.append(feats.cpu().numpy())
                labels_list.append(labels.numpy())
                total += labels.size(0)
                if total >= max_samples:
                    break

        feats = np.concatenate(feats_list, axis=0)[:max_samples]
        labels = np.concatenate(labels_list, axis=0)[:max_samples]
        return feats, labels

    real_feats, _ = collect_features(real_ds, max_samples)
    gan_feats, _ = collect_features(gan_ds, max_samples)

    feats = np.concatenate([real_feats, gan_feats], axis=0)
    domain_labels = np.concatenate([
        np.zeros(real_feats.shape[0], dtype=int),
        np.ones(gan_feats.shape[0], dtype=int),
    ])

    if feats.shape[0] < 10:
        print("Not enough samples for t-SNE, skipping.")
        return

    print(f"Running t-SNE on {feats.shape[0]} samples "
          f"(real={real_feats.shape[0]}, gan={gan_feats.shape[0]})")

    perplexity = min(30, feats.shape[0] // 4)
    tsne = TSNE(
        n_components=2,
        perplexity=perplexity,
        n_iter=1000,
        random_state=SEED,
        verbose=0
    )
    feats_2d = tsne.fit_transform(feats)

    plt.figure(figsize=(8, 6))
    colors = ["#1f77b4", "#ff7f0e"]
    labels = ["Real", "GAN Synthetic"]
    markers = ["o", "^"]

    for d in [0, 1]:
        mask = (domain_labels == d)
        if mask.sum() == 0:
            continue
        plt.scatter(
            feats_2d[mask, 0],
            feats_2d[mask, 1],
            c=colors[d],
            s=30,
            marker=markers[d],
            alpha=0.6,
            label=labels[d],
            edgecolors='black',
            linewidths=0.5
        )

    plt.title("t-SNE: Real vs GAN Synthetic (Fibrosis & Pneumonia)",
              fontsize=13, fontweight='bold')
    plt.xlabel("t-SNE Component 1", fontsize=11)
    plt.ylabel("t-SNE Component 2", fontsize=11)
    plt.legend(loc='best', fontsize=10)
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()


# ============================================================
# Main pipeline + zip & download
# ============================================================

print("\n" + "="*70)
print(" CV PROJECT PIPELINE: GAN + SWIN TRANSFORMER (pure GAN + 3-class clf)")
print("="*70)

# 1) Load classifier training data
full_trainval_samples = scan_trainval(DATA_ROOT, ALL_CLASSES)

if DEBUG_MODE:
    counts = defaultdict(int)
    limited = []
    for path, lbl in full_trainval_samples:
        cls_name = ALL_CLASSES[lbl]
        if counts[cls_name] < DEBUG_MAX_PER_CLASS:
            limited.append((path, lbl))
            counts[cls_name] += 1
    full_trainval_samples = limited
    print(f"\nDEBUG MODE: Limited to {len(full_trainval_samples)} samples")
    print("Per-class:", dict(counts))

# 2) Class weights + split
class_weights = compute_class_weights(full_trainval_samples)
train_samples, val_samples = stratified_split(full_trainval_samples, val_ratio=0.2)

# 3) Train cGAN on pure fibrosis/pneumonia + generate synthetic images
G, num_gan_classes = train_cgan()
generate_gan_synthetic(G, num_gan_classes)

# 4) Baseline classifier datasets (real only)
train_real_ds = PathLabelDataset(train_samples, transform=get_transforms(train=True))
val_real_ds = PathLabelDataset(val_samples, transform=get_transforms(train=False))

print("\n" + "="*70)
print(" BASELINE EXPERIMENTS (real only)")
print("="*70)

# Baseline CE
model_ce = train_classifier(
    train_real_ds, val_real_ds,
    name="Baseline_CE",
    num_epochs=SWIN_EPOCHS_BASELINE,
    loss_type="ce"
)
eval_on_test(model_ce, "Baseline CE")

# Baseline weighted CE (improved weights)
model_weighted = train_classifier(
    train_real_ds, val_real_ds,
    name="Baseline_Weighted_CE",
    num_epochs=SWIN_EPOCHS_BASELINE,
    loss_type="weighted",
    class_weights=class_weights
)
eval_on_test(model_weighted, "Baseline Weighted CE")

print("\n" + "="*70)
print(" GAN ABLATION EXPERIMENT (real + GAN, weighted CE, factor=2)")
print("="*70)

# 5) Single GAN ablation (conservative factor = 2.0)
train_gan, val_gan = build_gan_ablation_dataset(train_samples, val_samples, factor=2.0)
model_gan = train_classifier(
    train_gan, val_gan,
    name="GAN_Weighted_CE",
    num_epochs=SWIN_EPOCHS_ABLATION,
    loss_type="weighted",
    class_weights=class_weights
)
eval_on_test(model_gan, "GAN + Weighted CE")

# 6) Latent t-SNE (optional visualization for report)
if not DEBUG_MODE:
    run_latent_tsne()
else:
    print("\nSkipping t-SNE in DEBUG_MODE.")

print("\n" + "="*70)
print(" PIPELINE COMPLETE")
print("="*70)
print(f"Checkpoints (in Colab): {CHECKPOINT_DIR}")
print(f"GAN synthetic images (in Colab): {GAN_SYN_ROOT}")

# ============================================================
# Zip outputs and download to your Mac (Downloads folder)
# ============================================================
zip_path = "/content/CV_Project_outputs.zip"
print(f"\nZipping all outputs from {LOCAL_OUT} to {zip_path} ...")
shutil.make_archive("/content/CV_Project_outputs", "zip", LOCAL_OUT)

print("Starting download...")
files.download(zip_path)
print("Download triggered. Unzip in your Mac's Downloads/CV_Project.")